# æ•°æ®åŠ è½½æ¨¡å— - ä¼˜åŒ–çš„å¤§æ•°æ®é›†å¤„ç†
# åŒ…å«MarioDatasetç±»å’Œç›¸å…³çš„è§†é¢‘åºåˆ—æ„å»ºå‡½æ•°

from typing import Optional
import re
import os
import torch
from torch.utils.data import Dataset
from torchvision import transforms
from PIL import Image
from concurrent.futures import ProcessPoolExecutor

from torchvision.transforms import InterpolationMode


class MarioDataset(Dataset):
    """load mario dataset __init__ action and img paths,
     __getitem__  will return image and corresponding action"""
    """up to date: 2025-09-20 only load all frames in one directory,
     return array ofimages and actions"""
    # def __init__(self, data_path: str, image_size, num_workers=4, train_sample=1,num_frames=12):
    def __init__(self, cfg):
        self.data_path = cfg.data_path
        self.image_size = cfg.img_size
        self.num_workers_folders = cfg.num_workers_folders
        self.train_sample = cfg.train_sample
        self.num_frames = cfg.num_frames
        self.frame_interval = cfg.frame_interval  # æ·»åŠ  frame_interval å‚æ•°
        self.image_files = [] # image files path (xxx.png)
        self.actions = [] # action (0-255)
        self.nonterminals = []
        self._load_data()
        image_size = cfg.img_size
        self.transform = transforms.Compose([
            transforms.Resize((image_size, image_size),interpolation=InterpolationMode.NEAREST),
            # transforms.Resize((image_size, image_size)),
            transforms.ToTensor(), # [0, 1]
            transforms.Normalize(0.5, 0.5),  # [-1, 1]
        ])
        
        # é¢„è®¡ç®—æœ‰æ•ˆçš„è§†é¢‘åºåˆ—èµ·å§‹ä½ç½®ï¼ˆé—´éš” frame_intervalï¼‰
        self.valid_starts = []
        total_samples = len(self.image_files)
        for start in range(0, total_samples - self.num_frames + 1, self.frame_interval):
            self.valid_starts.append(start)
        
        print(f"ğŸ“Š valid video sequences: {len(self.valid_starts)} (interval {self.frame_interval} samples)")
        
    def _load_data(self):
        """load all png files and corresponding actions - optimized for large datasets"""
        print(f" data path is scanning: {self.data_path}")
        if not os.path.exists(self.data_path): 
            print(f"âŒ data path not found: {self.data_path}")
            return
        
        # ä½¿ç”¨å¤šè¿›ç¨‹æ‰«ææ–‡ä»¶
        import multiprocessing as mp
        
        # æ”¶é›†æ‰€æœ‰å­ç›®å½•
        subdirs = []
        for root, dirs, files in os.walk(self.data_path):
            if root != self.data_path and files:  # è·³è¿‡æ ¹ç›®å½•ï¼Œåªå¤„ç†æœ‰æ–‡ä»¶çš„å­ç›®å½•
                subdirs.append(root)
        
        print(f"Found {len(subdirs)} subdirectories to scan")
        
        # å¹¶è¡Œå¤„ç†æ¯ä¸ªå­ç›®å½•ï¼Œæ¯ä¸ªå­ç›®å½•å†…å·²æŒ‰å¸§å·æ’åº
        with ProcessPoolExecutor(max_workers=self.num_workers_folders) as executor:
            futures = [executor.submit(MarioDataset._scan_directory, subdir,self.train_sample) for subdir in subdirs]
            
            for future in futures:
                files, actions, nonterminals = future.result()
                self.image_files.extend(files)
                self.actions.extend(actions)
                self.nonterminals.extend(nonterminals)
        print(f"âœ… Loaded {len(self.image_files)} valid images from {len(subdirs)} levels")
    
    @staticmethod
    def _scan_directory(directory,train_sample):
        """æ‰«æå•ä¸ªç›®å½•ï¼Œè¿”å›æ–‡ä»¶è·¯å¾„å’ŒåŠ¨ä½œï¼ŒæŒ‰å¸§å·æ’åº"""

        file_data = []  # å­˜å‚¨(file_path, action, nonterminal, frame_num)çš„åˆ—è¡¨
        
        # é¦–å…ˆæ”¶é›†æ‰€æœ‰æ–‡ä»¶å¹¶æŒ‰å¸§å·æ’åº
        all_files = []
        for file in os.listdir(directory):
            if file.lower().endswith('.png'):
                file_path = os.path.join(directory, file)
                action, nonterminal = MarioDataset._extract_action_nonterminal_from_filename_static(file)
                frame_num = MarioDataset._extract_frame_number_from_filename_static(file)
                if action is not None and frame_num is not None:
                    all_files.append((file_path, action, nonterminal, frame_num))
        
        # æŒ‰å¸§å·æ’åº
        all_files.sort(key=lambda x: x[3])
        
        # æŒ‰é¡ºåºè¿›è¡Œè·³å¸§å¤„ç†ï¼ˆåŸºäºå®é™…å¸§å·å·®å€¼ï¼‰
        # é€»è¾‘ï¼šåªä¿ç•™ä¸ä¸Šä¸€ä¸ªæ·»åŠ å¸§çš„å·®å€¼ > train_sample çš„å¸§
        # - nt=0ï¼ˆç»“æŸå¸§ï¼‰æ€»æ˜¯æ·»åŠ 
        # - nt=1æ—¶ï¼Œå¦‚æœå½“å‰å¸§ä¸ä¸Šä¸ªå·²æ·»åŠ å¸§çš„å¸§å·å·®å€¼ > train_sampleï¼Œæ‰æ·»åŠ 
        # è¿™æ ·è‡ªç„¶è·³è¿‡å¯†é›†å¸§ï¼Œä¿ç•™ç¨€ç–å¸§
        last_added_frame_num = None  # è®°å½•ä¸Šä¸€ä¸ªæ·»åŠ çš„å¸§å·
        
        for file_path, action, nonterminal, frame_num in all_files:
            # nt=0ï¼ˆæ¸¸æˆç»“æŸå¸§ï¼‰æ€»æ˜¯æ·»åŠ 
            if not nonterminal:
                file_data.append((file_path, action, nonterminal, frame_num))
                last_added_frame_num = frame_num
            # nt=1ï¼ˆæ¸¸æˆè¿›è¡Œä¸­ï¼‰
            elif last_added_frame_num is None:
                # ç¬¬ä¸€å¸§ï¼Œç›´æ¥æ·»åŠ 
                file_data.append((file_path, action, nonterminal, frame_num))
                last_added_frame_num = frame_num
            elif frame_num - last_added_frame_num > train_sample:
                # å¸§å·å·®å€¼>train_sampleï¼Œæ·»åŠ 
                file_data.append((file_path, action, nonterminal, frame_num))
                last_added_frame_num = frame_num
            # å¦åˆ™è·³è¿‡ï¼ˆå¸§å·å·®å€¼<=train_sampleä¸”nt=1ï¼‰
        
        # å°†æœ€åä¸€å¸§çš„nonterminalè®¾ç½®ä¸ºFalseï¼ˆæ¸¸æˆç»“æŸï¼‰
        if file_data:
            last_item = file_data[-1]
            file_data[-1] = (last_item[0], last_item[1], False, last_item[3])
        
        # åˆ†ç¦»æ•°æ®
        files = [item[0] for item in file_data]
        actions = [item[1] for item in file_data]
        nonterminals = [item[2] for item in file_data]
        
        return files, actions, nonterminals
    
    @staticmethod
    def _extract_frame_number_from_filename_static(filename: str) -> Optional[int]:
        """ä»æ–‡ä»¶åä¸­æå–å¸§å·"""
        pattern = r'_f(\d+)_'
        match = re.search(pattern, filename)
        if match:
            return int(match.group(1))
        return None
    
    @staticmethod
    def _extract_action_nonterminal_from_filename_static(filename: str) -> Optional[int]:
        """é™æ€æ–¹æ³•ç‰ˆæœ¬çš„åŠ¨ä½œæå–å‡½æ•°"""
        pattern1 = r'_a(\d+)_'
        pattern2 = r'_nt(\d+)'  # åŒ¹é…ntåé¢çš„æ•°å­—ï¼ˆåé¢å¯èƒ½æ˜¯ä¸‹åˆ’çº¿æˆ–ç‚¹å·ï¼‰
        match1 = re.search(pattern1, filename)
        match2 = re.search(pattern2, filename)
        if match1:
            action_mapped = int(match1.group(1))
            # action_mapped = MarioDataset._map_action_to_playgenaction_static(action)
        else:
            action_mapped = None
        
        # if match2:
        #     nonterminal = int(match2.group(1))  # ä¿®æ”¹ï¼šgroup(1)è€Œä¸æ˜¯group(2)
        #     nonterminal = nonterminal == 1
        # else:
        #     nonterminal = False
        if match2:
            nonterminal = True
        return action_mapped, nonterminal


    # @staticmethod
    # def _map_action_to_playgenaction_static(action: int) -> int:
    #     """é™æ€æ–¹æ³•ç‰ˆæœ¬çš„åŠ¨ä½œæ˜ å°„å‡½æ•°
    #     æ˜ å°„è§„åˆ™ï¼š
    #     - 0/45: æ— åŠ¨ä½œæˆ–æœªè¯†åˆ«
    #     - 1: å³ç§» (r)
    #     - 2: å‘å³è·³ (rj)
    #     - 3: å·¦ç§» (l)
    #     - 4: å‘å·¦è·³ (lj)
    #     - 5: åŸåœ°è·³ (j)
    #     - 6: åŠ é€Ÿæˆ–ä¸‹è¹² (b æˆ– bd)
    #     - 7: åŠ é€Ÿå‘å³ä¸‹ (brd)
    #     - 8: åŠ é€Ÿå‘å·¦ä¸‹ (bld)
    #     """
    #     if action == 0: # æ— åŠ¨ä½œ
    #         return 0
    #     if action == 2:
    #         return 1  #
    #     elif action == 148:
    #         return 2
    #     elif action == 48:
    #         return 3
    #     elif action == 176:
    #         return 4
    #     elif action == 144:
    #         return 5
    #     elif action in (16, 18):
    #         return 6
    #     elif action == 22:
    #         return 7
    #     elif action == 50:
    #         return 8
    #     else:
    #         return 45

    def __len__(self):
        """è¿”å›æœ‰æ•ˆçš„è§†é¢‘åºåˆ—æ•°é‡ï¼ˆä¸æ˜¯åŸå§‹æ ·æœ¬æ•°é‡ï¼‰"""
        return len(self.valid_starts)
    
    def __getitem__(self, idx):
        """get the data sample of the specified index - optimized for large datasets
        æ³¨æ„ï¼šidx æ˜¯ valid_starts ä¸­çš„ç´¢å¼•ï¼Œä¸æ˜¯åŸå§‹æ ·æœ¬ç´¢å¼•
        """
        if idx >= len(self.valid_starts):
            raise IndexError(f"Index {idx} out of range for dataset of size {len(self.valid_starts)}")

        # ä» valid_starts ä¸­è·å–çœŸå®çš„èµ·å§‹ç´¢å¼•
        start_idx = self.valid_starts[idx]
        end_idx = start_idx + self.num_frames

        # æ„å»ºå•ä¸ªè§†é¢‘åºåˆ—
        video_images = []
        video_actions = []
        video_nonterminals = []

        for cur_idx in range(start_idx, end_idx):
            # åŠ è½½å›¾åƒ - ä½¿ç”¨æ›´é«˜æ•ˆçš„å›¾åƒåŠ è½½
            image_path = self.image_files[cur_idx]
            try:
                # ä½¿ç”¨PILçš„ä¼˜åŒ–é€‰é¡¹
                image = Image.open(image_path).convert('RGB')
                image = self.transform(image)
            except Exception as e:
                print(f"Error loading image {image_path}: {e}")
                # è¿”å›ä¸€ä¸ªé»˜è®¤çš„é»‘è‰²å›¾åƒ
                image = torch.zeros(3, self.image_size, self.image_size)

            # è·å–åŠ¨ä½œ
            action = self.actions[cur_idx] if cur_idx < len(self.actions) else 0
            nonterminal = self.nonterminals[cur_idx] if cur_idx < len(self.nonterminals) else False
            video_images.append(image)
            video_actions.append(action)
            video_nonterminals.append(nonterminal)

        # è½¬æ¢ä¸ºtensor
        images_tensor = torch.stack(video_images, dim=0)  # [num_frames, 3, 128, 128]
        actions_tensor = torch.tensor(video_actions, dtype=torch.long).unsqueeze(-1)  # [num_frames, 1]
        nonterminals_tensor = torch.tensor(video_nonterminals, dtype=torch.bool)  # [num_frames]

        return images_tensor, actions_tensor, nonterminals_tensor


def build_video_sequence_batch(dataset, start_indices, num_frames):
    """æ‰¹é‡æ„å»ºè§†é¢‘åºåˆ—ï¼Œä¼˜åŒ–å¤§æ•°æ®é›†å¤„ç†"""
    batch_images = []
    batch_actions = []
    batch_nonterminals = []
    
    # æ‰¹é‡è·å–æ•°æ®
    for start_idx in start_indices:
        end_idx = start_idx + num_frames
        
        # æ„å»ºå•ä¸ªè§†é¢‘åºåˆ—
        video_images = []
        video_actions = []
        video_nonterminals = []
        
        for frame_idx in range(start_idx, end_idx):

            image, action, nonterminal = dataset[frame_idx]
            video_images.append(image)
            video_actions.append(action)
            video_nonterminals.append(nonterminal)
        
        # è½¬æ¢ä¸ºtensor
        images_tensor = torch.stack(video_images, dim=0).unsqueeze(0)  # [b, num_frames, 3, 128, 128]
        actions_tensor = torch.tensor(video_actions, dtype=torch.long).unsqueeze(0).unsqueeze(-1)  # [b, num_frames, 1]
        nonterminals_tensor = torch.tensor(video_nonterminals, dtype=torch.bool).unsqueeze(0)  # [b, num_frames]
        
        batch_images.append(images_tensor)
        batch_actions.append(actions_tensor)
        batch_nonterminals.append(nonterminals_tensor)
    
    return batch_images, batch_actions, batch_nonterminals


def build_img_batch(dataset, start_indices,batch_size):
    """æ‰¹é‡æ„å»ºå›¾ç‰‡è®­ç»ƒVAE"""
    batch_images = []
    # æ‰¹é‡è·å–æ•°æ®
    for idx in range(batch_size):
        image, _, _= dataset[start_indices+idx]
        batch_images.append(image)
    # è½¬æ¢ä¸ºtensor
    images_tensor = torch.stack(batch_images, dim=0)  # [b, 3, 256, 256]
    return images_tensor
